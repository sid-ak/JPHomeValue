{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_model_uptrend.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KRlH60U7gK2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd427e13-c291-4033-ea7a-ac9fa68d0be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files # google colab specific\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "UQOo3N9QgiiT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the csv file that contains the time series data of the Shiller Index\n",
        "# Create the dataframe\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/JPM/jphomevalue/jphomevalue/data/shiller/shiller_split/shiller_upward.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NP79JZh5gikb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "922804a3-ff25-48f8-be34-01a8830b07cf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   s_no     DATE      TPXRSA\n",
              "0     0  2012-02  126.265187\n",
              "1     1  2012-03  127.055604\n",
              "2     2  2012-04  128.918919\n",
              "3     3  2012-05  130.370998\n",
              "4     4  2012-06  131.672439"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50d32063-85e1-447d-83b5-78567a0ca54c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_no</th>\n",
              "      <th>DATE</th>\n",
              "      <th>TPXRSA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2012-02</td>\n",
              "      <td>126.265187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012-03</td>\n",
              "      <td>127.055604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2012-04</td>\n",
              "      <td>128.918919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2012-05</td>\n",
              "      <td>130.370998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2012-06</td>\n",
              "      <td>131.672439</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50d32063-85e1-447d-83b5-78567a0ca54c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50d32063-85e1-447d-83b5-78567a0ca54c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50d32063-85e1-447d-83b5-78567a0ca54c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index based on the prices\n",
        "df1 = df.reset_index()['TPXRSA']\n",
        "df1"
      ],
      "metadata": {
        "id": "nymcV0xmgim7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3b7e06-5aca-4cce-eef6-0cb48a25e53b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      126.265187\n",
              "1      127.055604\n",
              "2      128.918919\n",
              "3      130.370998\n",
              "4      131.672439\n",
              "          ...    \n",
              "102    235.632918\n",
              "103    238.226820\n",
              "104    241.910433\n",
              "105    245.020717\n",
              "106    248.775518\n",
              "Name: TPXRSA, Length: 107, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data for reference. \n",
        "plt.plot(df1)"
      ],
      "metadata": {
        "id": "7mAcQZqegipe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e229fc3d-bd65-46bb-dfa9-110671d60e1e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f922e5053d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data with the range 0 - 1\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "# Apply the scaler to the dataframe\n",
        "df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
        "\n",
        "# Print df1 to check the change\n",
        "print(df1)"
      ],
      "metadata": {
        "id": "HQrFNXdlgiru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100934a8-9ffc-43f9-9400-5659012af8d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.        ]\n",
            " [0.00645184]\n",
            " [0.02166129]\n",
            " [0.033514  ]\n",
            " [0.04413711]\n",
            " [0.0483963 ]\n",
            " [0.05451133]\n",
            " [0.05629725]\n",
            " [0.05760311]\n",
            " [0.06204435]\n",
            " [0.06866779]\n",
            " [0.08799684]\n",
            " [0.10145606]\n",
            " [0.12436843]\n",
            " [0.13805083]\n",
            " [0.14836015]\n",
            " [0.16503295]\n",
            " [0.18651196]\n",
            " [0.21066518]\n",
            " [0.21763751]\n",
            " [0.22455918]\n",
            " [0.23380061]\n",
            " [0.24178035]\n",
            " [0.25304794]\n",
            " [0.24986812]\n",
            " [0.24416401]\n",
            " [0.25392203]\n",
            " [0.26683066]\n",
            " [0.27534496]\n",
            " [0.27758053]\n",
            " [0.28197129]\n",
            " [0.28836109]\n",
            " [0.30204057]\n",
            " [0.31761384]\n",
            " [0.32069882]\n",
            " [0.32329223]\n",
            " [0.33123812]\n",
            " [0.34228245]\n",
            " [0.34622957]\n",
            " [0.34812697]\n",
            " [0.34838004]\n",
            " [0.35624617]\n",
            " [0.36548836]\n",
            " [0.37580048]\n",
            " [0.38727424]\n",
            " [0.39696401]\n",
            " [0.41148789]\n",
            " [0.42058543]\n",
            " [0.43292524]\n",
            " [0.44054141]\n",
            " [0.44900564]\n",
            " [0.45417689]\n",
            " [0.45912635]\n",
            " [0.46503066]\n",
            " [0.47393423]\n",
            " [0.48338828]\n",
            " [0.4981979 ]\n",
            " [0.51058613]\n",
            " [0.53047218]\n",
            " [0.5370608 ]\n",
            " [0.53781505]\n",
            " [0.53758641]\n",
            " [0.5462783 ]\n",
            " [0.55943559]\n",
            " [0.56531634]\n",
            " [0.57381416]\n",
            " [0.57916573]\n",
            " [0.59344018]\n",
            " [0.60202692]\n",
            " [0.61779256]\n",
            " [0.62661203]\n",
            " [0.63988029]\n",
            " [0.64679052]\n",
            " [0.65378036]\n",
            " [0.65843812]\n",
            " [0.66488025]\n",
            " [0.67678111]\n",
            " [0.68518954]\n",
            " [0.6941109 ]\n",
            " [0.70221882]\n",
            " [0.70547965]\n",
            " [0.70980461]\n",
            " [0.71272228]\n",
            " [0.72305668]\n",
            " [0.73586969]\n",
            " [0.74185721]\n",
            " [0.75146193]\n",
            " [0.75308129]\n",
            " [0.75813567]\n",
            " [0.76342595]\n",
            " [0.7697737 ]\n",
            " [0.77903635]\n",
            " [0.78897796]\n",
            " [0.79610327]\n",
            " [0.80368235]\n",
            " [0.80944432]\n",
            " [0.82247067]\n",
            " [0.83992806]\n",
            " [0.85275164]\n",
            " [0.85858292]\n",
            " [0.86170288]\n",
            " [0.8695988 ]\n",
            " [0.89272251]\n",
            " [0.91389544]\n",
            " [0.94396321]\n",
            " [0.96935115]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation and test set. Ratio: 6/1/3\n",
        "training_size = int(len(df1)*0.6)\n",
        "validation_size = int(len(df1)*0.75) \n",
        "test_size = int(len(df1))\n",
        "\n",
        "train_set = df1[0:training_size,:]\n",
        "validation_set = df1[training_size:validation_size,:]\n",
        "test_set = df1[validation_size:test_size,:1]\n",
        "\n"
      ],
      "metadata": {
        "id": "7-RFY8rPgit_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZyXB9Fadp7D",
        "outputId": "46ab67c8-caed-4017-9562-e9a3c772dc63"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check sizes and set sizes\n",
        "#training_size\n",
        "#validation_size \n",
        "#test_size\n",
        "print(train_set.shape)\n",
        "print(validation_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "id": "NFMvq31VgiwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d623aa77-7ac6-44bb-9f55-03392ed928ba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1)\n",
            "(16, 1)\n",
            "(27, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The current array of values needs to be converted into a dataset matrix\n",
        "def create_dmatrix(dataset, time_step=1):\n",
        "  data_X, data_Y = [], []\n",
        "  for i in range(len(dataset)-time_step-1):\n",
        "    k = dataset[i:(i + time_step), 0]\n",
        "    data_X.append(k)\n",
        "    data_Y.append(dataset[i + time_step, 0])\n",
        "  return np.array(data_X), np.array(data_Y)"
      ],
      "metadata": {
        "id": "FTaWKxTkgiy6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the function already created for the conversion, convert training, validation and test sets. \n",
        "time_step = 8\n",
        "X_train, Y_train = create_dmatrix(train_set, time_step)\n",
        "X_val, Y_val = create_dmatrix(validation_set, time_step)\n",
        "X_test, Y_test = create_dmatrix(test_set, time_step)\n",
        "\n",
        "print('X Train set shape:', X_train.shape)\n",
        "print('y Train set shape:', Y_train.shape)\n",
        "\n",
        "print('X Validation set shape:', X_val.shape)\n",
        "print('y Validation set shape:', Y_val.shape)\n",
        "\n",
        "print('X Test set shape:', X_test.shape)\n",
        "print('y Test set shape:', Y_test.shape)\n"
      ],
      "metadata": {
        "id": "GNnJWZcwgi8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db953874-ce32-4d36-9d08-a6fe7d44da89"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train set shape: (55, 8)\n",
            "y Train set shape: (55,)\n",
            "X Validation set shape: (7, 8)\n",
            "y Validation set shape: (7,)\n",
            "X Test set shape: (18, 8)\n",
            "y Test set shape: (18,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the matrixes created\n",
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KythFnfXCNw",
        "outputId": "42c30a7b-5248-4436-9091-18bb2b4fed26"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70547965, 0.70980461, 0.71272228, 0.72305668, 0.73586969,\n",
              "        0.74185721, 0.75146193, 0.75308129],\n",
              "       [0.70980461, 0.71272228, 0.72305668, 0.73586969, 0.74185721,\n",
              "        0.75146193, 0.75308129, 0.75813567],\n",
              "       [0.71272228, 0.72305668, 0.73586969, 0.74185721, 0.75146193,\n",
              "        0.75308129, 0.75813567, 0.76342595],\n",
              "       [0.72305668, 0.73586969, 0.74185721, 0.75146193, 0.75308129,\n",
              "        0.75813567, 0.76342595, 0.7697737 ],\n",
              "       [0.73586969, 0.74185721, 0.75146193, 0.75308129, 0.75813567,\n",
              "        0.76342595, 0.7697737 , 0.77903635],\n",
              "       [0.74185721, 0.75146193, 0.75308129, 0.75813567, 0.76342595,\n",
              "        0.7697737 , 0.77903635, 0.78897796],\n",
              "       [0.75146193, 0.75308129, 0.75813567, 0.76342595, 0.7697737 ,\n",
              "        0.77903635, 0.78897796, 0.79610327],\n",
              "       [0.75308129, 0.75813567, 0.76342595, 0.7697737 , 0.77903635,\n",
              "        0.78897796, 0.79610327, 0.80368235],\n",
              "       [0.75813567, 0.76342595, 0.7697737 , 0.77903635, 0.78897796,\n",
              "        0.79610327, 0.80368235, 0.80944432],\n",
              "       [0.76342595, 0.7697737 , 0.77903635, 0.78897796, 0.79610327,\n",
              "        0.80368235, 0.80944432, 0.82247067],\n",
              "       [0.7697737 , 0.77903635, 0.78897796, 0.79610327, 0.80368235,\n",
              "        0.80944432, 0.82247067, 0.83992806],\n",
              "       [0.77903635, 0.78897796, 0.79610327, 0.80368235, 0.80944432,\n",
              "        0.82247067, 0.83992806, 0.85275164],\n",
              "       [0.78897796, 0.79610327, 0.80368235, 0.80944432, 0.82247067,\n",
              "        0.83992806, 0.85275164, 0.85858292],\n",
              "       [0.79610327, 0.80368235, 0.80944432, 0.82247067, 0.83992806,\n",
              "        0.85275164, 0.85858292, 0.86170288],\n",
              "       [0.80368235, 0.80944432, 0.82247067, 0.83992806, 0.85275164,\n",
              "        0.85858292, 0.86170288, 0.8695988 ],\n",
              "       [0.80944432, 0.82247067, 0.83992806, 0.85275164, 0.85858292,\n",
              "        0.86170288, 0.8695988 , 0.89272251],\n",
              "       [0.82247067, 0.83992806, 0.85275164, 0.85858292, 0.86170288,\n",
              "        0.8695988 , 0.89272251, 0.91389544],\n",
              "       [0.83992806, 0.85275164, 0.85858292, 0.86170288, 0.8695988 ,\n",
              "        0.89272251, 0.91389544, 0.94396321]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to feed the dataset to the neural network the data must be in 3D\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "NTkZBoTbmRZp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "epochs = 500\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "OVf588vmm9jy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM MODEL ARCHITECTURE\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.Input(shape=(8, 1)),\n",
        "  # Masking layer, to ignore zeros.\n",
        "  # keras.layers.Masking(),\n",
        "  # 4 LSTM Layers with 16 units.\n",
        "  keras.layers.LSTM(units=45, return_sequences=True),\n",
        "  keras.layers.LSTM(units=45, return_sequences=True),\n",
        "  keras.layers.LSTM(units=45, return_sequences=True),\n",
        "  keras.layers.LSTM(units=45),\n",
        "  # Fully Connected Layer\n",
        "  keras.layers.Dense(units=1)\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3xYTfnX7mRcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b90f48-a5eb-4703-af1f-5108ec1ebfa3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_24 (LSTM)              (None, 8, 45)             8460      \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 8, 45)             16380     \n",
            "                                                                 \n",
            " lstm_26 (LSTM)              (None, 8, 45)             16380     \n",
            "                                                                 \n",
            " lstm_27 (LSTM)              (None, 45)                16380     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 46        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,646\n",
            "Trainable params: 57,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer Functions\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "model.compile(loss=mse, optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=[rmse])"
      ],
      "metadata": {
        "id": "efwTmK16oM0f"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks.\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=100, verbose=1), \n",
        "            ModelCheckpoint(filepath='/content/sample_data/lstm-model-uptrend.h5', verbose=1, monitor='val_loss', save_best_only=True, save_weights_only=False)]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x=X_train, y=Y_train, validation_data =(X_val, Y_val), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "ADW-xwhOmRel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba89c50a-0a44-4084-b004-b6ed6e2a6070"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1175 - root_mean_squared_error: 0.3427\n",
            "Epoch 1: val_loss improved from inf to 0.39075, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 11s 2s/step - loss: 0.1175 - root_mean_squared_error: 0.3427 - val_loss: 0.3907 - val_root_mean_squared_error: 0.6251\n",
            "Epoch 2/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0938 - root_mean_squared_error: 0.3063\n",
            "Epoch 2: val_loss improved from 0.39075 to 0.32891, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0949 - root_mean_squared_error: 0.3081 - val_loss: 0.3289 - val_root_mean_squared_error: 0.5735\n",
            "Epoch 3/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0749 - root_mean_squared_error: 0.2737\n",
            "Epoch 3: val_loss improved from 0.32891 to 0.25385, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0716 - root_mean_squared_error: 0.2675 - val_loss: 0.2538 - val_root_mean_squared_error: 0.5038\n",
            "Epoch 4/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0597 - root_mean_squared_error: 0.2444\n",
            "Epoch 4: val_loss improved from 0.25385 to 0.16494, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0467 - root_mean_squared_error: 0.2160 - val_loss: 0.1649 - val_root_mean_squared_error: 0.4061\n",
            "Epoch 5/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0277 - root_mean_squared_error: 0.1663\n",
            "Epoch 5: val_loss improved from 0.16494 to 0.07155, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0218 - root_mean_squared_error: 0.1478 - val_loss: 0.0716 - val_root_mean_squared_error: 0.2675\n",
            "Epoch 6/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0114 - root_mean_squared_error: 0.1065\n",
            "Epoch 6: val_loss improved from 0.07155 to 0.01087, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0102 - root_mean_squared_error: 0.1010 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
            "Epoch 7/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0204 - root_mean_squared_error: 0.1430\n",
            "Epoch 7: val_loss improved from 0.01087 to 0.00404, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
            "Epoch 8/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0180 - root_mean_squared_error: 0.1343\n",
            "Epoch 8: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0227 - root_mean_squared_error: 0.1508 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
            "Epoch 9/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0143 - root_mean_squared_error: 0.1197\n",
            "Epoch 9: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0134 - root_mean_squared_error: 0.1159 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091\n",
            "Epoch 10/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0980\n",
            "Epoch 10: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954 - val_loss: 0.0738 - val_root_mean_squared_error: 0.2717\n",
            "Epoch 11/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0108 - root_mean_squared_error: 0.1041\n",
            "Epoch 11: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0104 - root_mean_squared_error: 0.1022 - val_loss: 0.0940 - val_root_mean_squared_error: 0.3065\n",
            "Epoch 12/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0114 - root_mean_squared_error: 0.1070\n",
            "Epoch 12: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0129 - root_mean_squared_error: 0.1135 - val_loss: 0.1006 - val_root_mean_squared_error: 0.3172\n",
            "Epoch 13/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0158 - root_mean_squared_error: 0.1256\n",
            "Epoch 13: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0135 - root_mean_squared_error: 0.1160 - val_loss: 0.0934 - val_root_mean_squared_error: 0.3055\n",
            "Epoch 14/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0118 - root_mean_squared_error: 0.1085\n",
            "Epoch 14: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0773 - val_root_mean_squared_error: 0.2780\n",
            "Epoch 15/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.1000\n",
            "Epoch 15: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0097 - root_mean_squared_error: 0.0987 - val_loss: 0.0551 - val_root_mean_squared_error: 0.2346\n",
            "Epoch 16/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0077 - root_mean_squared_error: 0.0878\n",
            "Epoch 16: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
            "Epoch 17/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - root_mean_squared_error: 0.0761\n",
            "Epoch 17: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - root_mean_squared_error: 0.0833 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1359\n",
            "Epoch 18/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0071 - root_mean_squared_error: 0.0842\n",
            "Epoch 18: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0073 - root_mean_squared_error: 0.0856 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
            "Epoch 19/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0063 - root_mean_squared_error: 0.0793\n",
            "Epoch 19: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
            "Epoch 20/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0076 - root_mean_squared_error: 0.0869\n",
            "Epoch 20: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
            "Epoch 21/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0052 - root_mean_squared_error: 0.0720\n",
            "Epoch 21: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0045 - root_mean_squared_error: 0.0668 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
            "Epoch 22/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034 - root_mean_squared_error: 0.0582\n",
            "Epoch 22: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0037 - root_mean_squared_error: 0.0608 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
            "Epoch 23/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0037 - root_mean_squared_error: 0.0605\n",
            "Epoch 23: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0034 - root_mean_squared_error: 0.0580 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1336\n",
            "Epoch 24/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032 - root_mean_squared_error: 0.0569\n",
            "Epoch 24: val_loss did not improve from 0.00404\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0027 - root_mean_squared_error: 0.0522 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
            "Epoch 25/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019 - root_mean_squared_error: 0.0431\n",
            "Epoch 25: val_loss improved from 0.00404 to 0.00272, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0018 - root_mean_squared_error: 0.0425 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0522\n",
            "Epoch 26/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - root_mean_squared_error: 0.0338\n",
            "Epoch 26: val_loss improved from 0.00272 to 0.00006, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 5.6052e-05 - val_root_mean_squared_error: 0.0075\n",
            "Epoch 27/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3413e-04 - root_mean_squared_error: 0.0289\n",
            "Epoch 27: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 9.9424e-04 - root_mean_squared_error: 0.0315 - val_loss: 5.2346e-04 - val_root_mean_squared_error: 0.0229\n",
            "Epoch 28/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1500e-04 - root_mean_squared_error: 0.0248\n",
            "Epoch 28: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 7.2664e-04 - root_mean_squared_error: 0.0270 - val_loss: 5.5463e-04 - val_root_mean_squared_error: 0.0236\n",
            "Epoch 29/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4380e-04 - root_mean_squared_error: 0.0211\n",
            "Epoch 29: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 4.3548e-04 - root_mean_squared_error: 0.0209 - val_loss: 1.9415e-04 - val_root_mean_squared_error: 0.0139\n",
            "Epoch 30/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2772e-04 - root_mean_squared_error: 0.0207\n",
            "Epoch 30: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.7132e-04 - root_mean_squared_error: 0.0217 - val_loss: 2.7123e-04 - val_root_mean_squared_error: 0.0165\n",
            "Epoch 31/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7743e-04 - root_mean_squared_error: 0.0279\n",
            "Epoch 31: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 5.9237e-04 - root_mean_squared_error: 0.0243 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0356\n",
            "Epoch 32/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.3128e-04 - root_mean_squared_error: 0.0251\n",
            "Epoch 32: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 5.6629e-04 - root_mean_squared_error: 0.0238 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
            "Epoch 33/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8104e-04 - root_mean_squared_error: 0.0241\n",
            "Epoch 33: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 6.1847e-04 - root_mean_squared_error: 0.0249 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
            "Epoch 34/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9581e-04 - root_mean_squared_error: 0.0264\n",
            "Epoch 34: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 6.6997e-04 - root_mean_squared_error: 0.0259 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0675\n",
            "Epoch 35/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9213e-04 - root_mean_squared_error: 0.0243\n",
            "Epoch 35: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 5.7106e-04 - root_mean_squared_error: 0.0239 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0476\n",
            "Epoch 36/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6950e-04 - root_mean_squared_error: 0.0277\n",
            "Epoch 36: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 5.1967e-04 - root_mean_squared_error: 0.0228 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0327\n",
            "Epoch 37/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4369e-04 - root_mean_squared_error: 0.0211\n",
            "Epoch 37: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 4.8334e-04 - root_mean_squared_error: 0.0220 - val_loss: 7.7838e-04 - val_root_mean_squared_error: 0.0279\n",
            "Epoch 38/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9267e-04 - root_mean_squared_error: 0.0198\n",
            "Epoch 38: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 4.1750e-04 - root_mean_squared_error: 0.0204 - val_loss: 9.9734e-04 - val_root_mean_squared_error: 0.0316\n",
            "Epoch 39/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8365e-04 - root_mean_squared_error: 0.0220\n",
            "Epoch 39: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.7655e-04 - root_mean_squared_error: 0.0194 - val_loss: 9.7589e-04 - val_root_mean_squared_error: 0.0312\n",
            "Epoch 40/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0830e-04 - root_mean_squared_error: 0.0202\n",
            "Epoch 40: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3.8111e-04 - root_mean_squared_error: 0.0195 - val_loss: 5.9731e-04 - val_root_mean_squared_error: 0.0244\n",
            "Epoch 41/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4203e-04 - root_mean_squared_error: 0.0185\n",
            "Epoch 41: val_loss did not improve from 0.00006\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.7886e-04 - root_mean_squared_error: 0.0195 - val_loss: 1.7637e-04 - val_root_mean_squared_error: 0.0133\n",
            "Epoch 42/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8067e-04 - root_mean_squared_error: 0.0168\n",
            "Epoch 42: val_loss improved from 0.00006 to 0.00006, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 3.6951e-04 - root_mean_squared_error: 0.0192 - val_loss: 5.5352e-05 - val_root_mean_squared_error: 0.0074\n",
            "Epoch 43/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2961e-04 - root_mean_squared_error: 0.0230\n",
            "Epoch 43: val_loss improved from 0.00006 to 0.00004, saving model to /content/sample_data/lstm-model-uptrend.h5\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 3.9021e-04 - root_mean_squared_error: 0.0198 - val_loss: 4.4805e-05 - val_root_mean_squared_error: 0.0067\n",
            "Epoch 44/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6738e-04 - root_mean_squared_error: 0.0164\n",
            "Epoch 44: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.9194e-04 - root_mean_squared_error: 0.0198 - val_loss: 6.4766e-05 - val_root_mean_squared_error: 0.0080\n",
            "Epoch 45/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4270e-04 - root_mean_squared_error: 0.0185\n",
            "Epoch 45: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.8662e-04 - root_mean_squared_error: 0.0197 - val_loss: 1.7985e-04 - val_root_mean_squared_error: 0.0134\n",
            "Epoch 46/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.0274e-04 - root_mean_squared_error: 0.0224\n",
            "Epoch 46: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 4.0015e-04 - root_mean_squared_error: 0.0200 - val_loss: 2.3915e-04 - val_root_mean_squared_error: 0.0155\n",
            "Epoch 47/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6676e-04 - root_mean_squared_error: 0.0163\n",
            "Epoch 47: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.9081e-04 - root_mean_squared_error: 0.0198 - val_loss: 1.3175e-04 - val_root_mean_squared_error: 0.0115\n",
            "Epoch 48/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4201e-04 - root_mean_squared_error: 0.0210\n",
            "Epoch 48: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.7608e-04 - root_mean_squared_error: 0.0194 - val_loss: 8.1468e-05 - val_root_mean_squared_error: 0.0090\n",
            "Epoch 49/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1827e-04 - root_mean_squared_error: 0.0228\n",
            "Epoch 49: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.7772e-04 - root_mean_squared_error: 0.0194 - val_loss: 9.2024e-05 - val_root_mean_squared_error: 0.0096\n",
            "Epoch 50/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1006e-04 - root_mean_squared_error: 0.0176\n",
            "Epoch 50: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.7565e-04 - root_mean_squared_error: 0.0194 - val_loss: 2.3569e-04 - val_root_mean_squared_error: 0.0154\n",
            "Epoch 51/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5655e-04 - root_mean_squared_error: 0.0214\n",
            "Epoch 51: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6390e-04 - root_mean_squared_error: 0.0191 - val_loss: 3.8124e-04 - val_root_mean_squared_error: 0.0195\n",
            "Epoch 52/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5953e-04 - root_mean_squared_error: 0.0190\n",
            "Epoch 52: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6334e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.7295e-04 - val_root_mean_squared_error: 0.0217\n",
            "Epoch 53/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9501e-04 - root_mean_squared_error: 0.0172\n",
            "Epoch 53: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3.6603e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.3246e-04 - val_root_mean_squared_error: 0.0208\n",
            "Epoch 54/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6491e-04 - root_mean_squared_error: 0.0163\n",
            "Epoch 54: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.6314e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.0183e-04 - val_root_mean_squared_error: 0.0200\n",
            "Epoch 55/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8293e-04 - root_mean_squared_error: 0.0220\n",
            "Epoch 55: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.6513e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.3307e-04 - val_root_mean_squared_error: 0.0208\n",
            "Epoch 56/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9538e-04 - root_mean_squared_error: 0.0172\n",
            "Epoch 56: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6582e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.9528e-04 - val_root_mean_squared_error: 0.0223\n",
            "Epoch 57/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8242e-04 - root_mean_squared_error: 0.0196\n",
            "Epoch 57: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 3.6627e-04 - root_mean_squared_error: 0.0191 - val_loss: 5.1630e-04 - val_root_mean_squared_error: 0.0227\n",
            "Epoch 58/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1135e-04 - root_mean_squared_error: 0.0176\n",
            "Epoch 58: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6601e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.4796e-04 - val_root_mean_squared_error: 0.0212\n",
            "Epoch 59/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7383e-04 - root_mean_squared_error: 0.0165\n",
            "Epoch 59: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6491e-04 - root_mean_squared_error: 0.0191 - val_loss: 4.1517e-04 - val_root_mean_squared_error: 0.0204\n",
            "Epoch 60/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8625e-04 - root_mean_squared_error: 0.0169\n",
            "Epoch 60: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.6360e-04 - root_mean_squared_error: 0.0191 - val_loss: 3.6360e-04 - val_root_mean_squared_error: 0.0191\n",
            "Epoch 61/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0383e-04 - root_mean_squared_error: 0.0201\n",
            "Epoch 61: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6234e-04 - root_mean_squared_error: 0.0190 - val_loss: 3.1038e-04 - val_root_mean_squared_error: 0.0176\n",
            "Epoch 62/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.0621e-04 - root_mean_squared_error: 0.0175\n",
            "Epoch 62: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 3.6212e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.8106e-04 - val_root_mean_squared_error: 0.0168\n",
            "Epoch 63/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4170e-04 - root_mean_squared_error: 0.0185\n",
            "Epoch 63: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6269e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.4824e-04 - val_root_mean_squared_error: 0.0158\n",
            "Epoch 64/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7009e-04 - root_mean_squared_error: 0.0217\n",
            "Epoch 64: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.6182e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.6059e-04 - val_root_mean_squared_error: 0.0161\n",
            "Epoch 65/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6047e-04 - root_mean_squared_error: 0.0190\n",
            "Epoch 65: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6682e-04 - root_mean_squared_error: 0.0192 - val_loss: 2.5245e-04 - val_root_mean_squared_error: 0.0159\n",
            "Epoch 66/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9256e-04 - root_mean_squared_error: 0.0198\n",
            "Epoch 66: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.6135e-04 - root_mean_squared_error: 0.0190 - val_loss: 3.2399e-04 - val_root_mean_squared_error: 0.0180\n",
            "Epoch 67/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5404e-04 - root_mean_squared_error: 0.0159\n",
            "Epoch 67: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6594e-04 - root_mean_squared_error: 0.0191 - val_loss: 3.3207e-04 - val_root_mean_squared_error: 0.0182\n",
            "Epoch 68/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0651e-04 - root_mean_squared_error: 0.0202\n",
            "Epoch 68: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 3.6231e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.0744e-04 - val_root_mean_squared_error: 0.0144\n",
            "Epoch 69/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6145e-04 - root_mean_squared_error: 0.0190\n",
            "Epoch 69: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.7242e-04 - root_mean_squared_error: 0.0193 - val_loss: 1.3963e-04 - val_root_mean_squared_error: 0.0118\n",
            "Epoch 70/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4842e-04 - root_mean_squared_error: 0.0212\n",
            "Epoch 70: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6904e-04 - root_mean_squared_error: 0.0192 - val_loss: 2.2293e-04 - val_root_mean_squared_error: 0.0149\n",
            "Epoch 71/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4380e-04 - root_mean_squared_error: 0.0211\n",
            "Epoch 71: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 3.6197e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.6471e-04 - val_root_mean_squared_error: 0.0163\n",
            "Epoch 72/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8240e-04 - root_mean_squared_error: 0.0168\n",
            "Epoch 72: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.6184e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.7714e-04 - val_root_mean_squared_error: 0.0166\n",
            "Epoch 73/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3271e-04 - root_mean_squared_error: 0.0182\n",
            "Epoch 73: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6261e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.6871e-04 - val_root_mean_squared_error: 0.0164\n",
            "Epoch 74/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1464e-04 - root_mean_squared_error: 0.0177\n",
            "Epoch 74: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.6174e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.9868e-04 - val_root_mean_squared_error: 0.0141\n",
            "Epoch 75/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7914e-04 - root_mean_squared_error: 0.0195\n",
            "Epoch 75: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 3.6087e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.4470e-04 - val_root_mean_squared_error: 0.0120\n",
            "Epoch 76/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2982e-04 - root_mean_squared_error: 0.0182\n",
            "Epoch 76: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 3.6581e-04 - root_mean_squared_error: 0.0191 - val_loss: 1.8454e-04 - val_root_mean_squared_error: 0.0136\n",
            "Epoch 77/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.9224e-04 - root_mean_squared_error: 0.0139\n",
            "Epoch 77: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 3.6132e-04 - root_mean_squared_error: 0.0190 - val_loss: 3.0062e-04 - val_root_mean_squared_error: 0.0173\n",
            "Epoch 78/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7396e-04 - root_mean_squared_error: 0.0193\n",
            "Epoch 78: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6149e-04 - root_mean_squared_error: 0.0190 - val_loss: 3.2843e-04 - val_root_mean_squared_error: 0.0181\n",
            "Epoch 79/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5718e-04 - root_mean_squared_error: 0.0214\n",
            "Epoch 79: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6402e-04 - root_mean_squared_error: 0.0191 - val_loss: 2.7312e-04 - val_root_mean_squared_error: 0.0165\n",
            "Epoch 80/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8425e-04 - root_mean_squared_error: 0.0196\n",
            "Epoch 80: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.6437e-04 - root_mean_squared_error: 0.0191 - val_loss: 2.1395e-04 - val_root_mean_squared_error: 0.0146\n",
            "Epoch 81/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2090e-04 - root_mean_squared_error: 0.0205\n",
            "Epoch 81: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.6034e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1914e-04 - val_root_mean_squared_error: 0.0148\n",
            "Epoch 82/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4495e-04 - root_mean_squared_error: 0.0186\n",
            "Epoch 82: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6022e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1283e-04 - val_root_mean_squared_error: 0.0146\n",
            "Epoch 83/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7550e-04 - root_mean_squared_error: 0.0194\n",
            "Epoch 83: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6155e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1087e-04 - val_root_mean_squared_error: 0.0145\n",
            "Epoch 84/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7846e-04 - root_mean_squared_error: 0.0195\n",
            "Epoch 84: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.5985e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.4856e-04 - val_root_mean_squared_error: 0.0158\n",
            "Epoch 85/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7579e-04 - root_mean_squared_error: 0.0194\n",
            "Epoch 85: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.6185e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.3620e-04 - val_root_mean_squared_error: 0.0154\n",
            "Epoch 86/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7031e-04 - root_mean_squared_error: 0.0164\n",
            "Epoch 86: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6062e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.6754e-04 - val_root_mean_squared_error: 0.0129\n",
            "Epoch 87/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0526e-04 - root_mean_squared_error: 0.0201\n",
            "Epoch 87: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6003e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.1985e-04 - val_root_mean_squared_error: 0.0109\n",
            "Epoch 88/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5974e-04 - root_mean_squared_error: 0.0214\n",
            "Epoch 88: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.6336e-04 - root_mean_squared_error: 0.0191 - val_loss: 1.3284e-04 - val_root_mean_squared_error: 0.0115\n",
            "Epoch 89/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7577e-04 - root_mean_squared_error: 0.0218\n",
            "Epoch 89: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6082e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.8416e-04 - val_root_mean_squared_error: 0.0136\n",
            "Epoch 90/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3731e-04 - root_mean_squared_error: 0.0184\n",
            "Epoch 90: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.6081e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.4333e-04 - val_root_mean_squared_error: 0.0156\n",
            "Epoch 91/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.9299e-04 - root_mean_squared_error: 0.0222\n",
            "Epoch 91: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6131e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.0867e-04 - val_root_mean_squared_error: 0.0144\n",
            "Epoch 92/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8020e-04 - root_mean_squared_error: 0.0195\n",
            "Epoch 92: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3.6202e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.7243e-04 - val_root_mean_squared_error: 0.0131\n",
            "Epoch 93/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6336e-04 - root_mean_squared_error: 0.0191\n",
            "Epoch 93: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.5971e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.0298e-04 - val_root_mean_squared_error: 0.0142\n",
            "Epoch 94/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7892e-04 - root_mean_squared_error: 0.0167\n",
            "Epoch 94: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.6032e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1521e-04 - val_root_mean_squared_error: 0.0147\n",
            "Epoch 95/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7896e-04 - root_mean_squared_error: 0.0195\n",
            "Epoch 95: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.5943e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.3345e-04 - val_root_mean_squared_error: 0.0153\n",
            "Epoch 96/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3965e-04 - root_mean_squared_error: 0.0184\n",
            "Epoch 96: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6095e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.0071e-04 - val_root_mean_squared_error: 0.0142\n",
            "Epoch 97/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2918e-04 - root_mean_squared_error: 0.0207\n",
            "Epoch 97: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6083e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.4013e-04 - val_root_mean_squared_error: 0.0118\n",
            "Epoch 98/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9278e-04 - root_mean_squared_error: 0.0171\n",
            "Epoch 98: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6020e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.1143e-04 - val_root_mean_squared_error: 0.0106\n",
            "Epoch 99/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7626e-04 - root_mean_squared_error: 0.0218\n",
            "Epoch 99: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6243e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.7043e-04 - val_root_mean_squared_error: 0.0131\n",
            "Epoch 100/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9950e-04 - root_mean_squared_error: 0.0200\n",
            "Epoch 100: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 3.5905e-04 - root_mean_squared_error: 0.0189 - val_loss: 2.4653e-04 - val_root_mean_squared_error: 0.0157\n",
            "Epoch 101/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.4408e-04 - root_mean_squared_error: 0.0156\n",
            "Epoch 101: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.6043e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.6668e-04 - val_root_mean_squared_error: 0.0163\n",
            "Epoch 102/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7500e-04 - root_mean_squared_error: 0.0166\n",
            "Epoch 102: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.6152e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1919e-04 - val_root_mean_squared_error: 0.0148\n",
            "Epoch 103/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6330e-04 - root_mean_squared_error: 0.0191\n",
            "Epoch 103: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6130e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.8421e-04 - val_root_mean_squared_error: 0.0136\n",
            "Epoch 104/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2153e-04 - root_mean_squared_error: 0.0205\n",
            "Epoch 104: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 3.5840e-04 - root_mean_squared_error: 0.0189 - val_loss: 1.3352e-04 - val_root_mean_squared_error: 0.0116\n",
            "Epoch 105/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1364e-04 - root_mean_squared_error: 0.0203\n",
            "Epoch 105: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6190e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.2898e-04 - val_root_mean_squared_error: 0.0114\n",
            "Epoch 106/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8682e-04 - root_mean_squared_error: 0.0197\n",
            "Epoch 106: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6084e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.0847e-04 - val_root_mean_squared_error: 0.0144\n",
            "Epoch 107/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7690e-04 - root_mean_squared_error: 0.0194\n",
            "Epoch 107: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.5952e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.3369e-04 - val_root_mean_squared_error: 0.0153\n",
            "Epoch 108/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4956e-04 - root_mean_squared_error: 0.0187\n",
            "Epoch 108: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.5972e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.9344e-04 - val_root_mean_squared_error: 0.0139\n",
            "Epoch 109/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8198e-04 - root_mean_squared_error: 0.0195\n",
            "Epoch 109: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.6128e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.4465e-04 - val_root_mean_squared_error: 0.0120\n",
            "Epoch 110/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4773e-04 - root_mean_squared_error: 0.0186\n",
            "Epoch 110: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.5831e-04 - root_mean_squared_error: 0.0189 - val_loss: 1.1083e-04 - val_root_mean_squared_error: 0.0105\n",
            "Epoch 111/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.5503e-04 - root_mean_squared_error: 0.0188\n",
            "Epoch 111: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.6506e-04 - root_mean_squared_error: 0.0191 - val_loss: 1.2013e-04 - val_root_mean_squared_error: 0.0110\n",
            "Epoch 112/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1737e-04 - root_mean_squared_error: 0.0204\n",
            "Epoch 112: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6062e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.3746e-04 - val_root_mean_squared_error: 0.0154\n",
            "Epoch 113/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2722e-04 - root_mean_squared_error: 0.0181\n",
            "Epoch 113: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6277e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1336e-04 - val_root_mean_squared_error: 0.0146\n",
            "Epoch 114/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2698e-04 - root_mean_squared_error: 0.0181\n",
            "Epoch 114: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.6386e-04 - root_mean_squared_error: 0.0191 - val_loss: 1.1288e-04 - val_root_mean_squared_error: 0.0106\n",
            "Epoch 115/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3740e-04 - root_mean_squared_error: 0.0184\n",
            "Epoch 115: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6065e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.3295e-04 - val_root_mean_squared_error: 0.0115\n",
            "Epoch 116/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2634e-04 - root_mean_squared_error: 0.0181\n",
            "Epoch 116: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.5850e-04 - root_mean_squared_error: 0.0189 - val_loss: 1.9142e-04 - val_root_mean_squared_error: 0.0138\n",
            "Epoch 117/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8563e-04 - root_mean_squared_error: 0.0196\n",
            "Epoch 117: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6399e-04 - root_mean_squared_error: 0.0191 - val_loss: 2.4197e-04 - val_root_mean_squared_error: 0.0156\n",
            "Epoch 118/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6851e-04 - root_mean_squared_error: 0.0192\n",
            "Epoch 118: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6867e-04 - root_mean_squared_error: 0.0192 - val_loss: 1.2181e-04 - val_root_mean_squared_error: 0.0110\n",
            "Epoch 119/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7190e-04 - root_mean_squared_error: 0.0193\n",
            "Epoch 119: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.5933e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.1595e-04 - val_root_mean_squared_error: 0.0108\n",
            "Epoch 120/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2899e-04 - root_mean_squared_error: 0.0181\n",
            "Epoch 120: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.5997e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.0763e-04 - val_root_mean_squared_error: 0.0104\n",
            "Epoch 121/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3984e-04 - root_mean_squared_error: 0.0184\n",
            "Epoch 121: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.5953e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.1185e-04 - val_root_mean_squared_error: 0.0106\n",
            "Epoch 122/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1532e-04 - root_mean_squared_error: 0.0178\n",
            "Epoch 122: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.5938e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.2437e-04 - val_root_mean_squared_error: 0.0112\n",
            "Epoch 123/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8031e-04 - root_mean_squared_error: 0.0195\n",
            "Epoch 123: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 3.6216e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.2036e-04 - val_root_mean_squared_error: 0.0110\n",
            "Epoch 124/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4474e-04 - root_mean_squared_error: 0.0186\n",
            "Epoch 124: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6070e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.1943e-04 - val_root_mean_squared_error: 0.0109\n",
            "Epoch 125/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.9933e-04 - root_mean_squared_error: 0.0173\n",
            "Epoch 125: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.5987e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.7872e-04 - val_root_mean_squared_error: 0.0134\n",
            "Epoch 126/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4109e-04 - root_mean_squared_error: 0.0185\n",
            "Epoch 126: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.6133e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.6648e-04 - val_root_mean_squared_error: 0.0129\n",
            "Epoch 127/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4322e-04 - root_mean_squared_error: 0.0185\n",
            "Epoch 127: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 3.6120e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.1213e-04 - val_root_mean_squared_error: 0.0146\n",
            "Epoch 128/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2142e-04 - root_mean_squared_error: 0.0179\n",
            "Epoch 128: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6023e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.3533e-04 - val_root_mean_squared_error: 0.0153\n",
            "Epoch 129/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.3721e-04 - root_mean_squared_error: 0.0154\n",
            "Epoch 129: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.6088e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.2189e-04 - val_root_mean_squared_error: 0.0149\n",
            "Epoch 130/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.8804e-04 - root_mean_squared_error: 0.0170\n",
            "Epoch 130: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.5959e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.2245e-04 - val_root_mean_squared_error: 0.0111\n",
            "Epoch 131/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8295e-04 - root_mean_squared_error: 0.0196\n",
            "Epoch 131: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6026e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.0565e-04 - val_root_mean_squared_error: 0.0103\n",
            "Epoch 132/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.1923e-04 - root_mean_squared_error: 0.0179\n",
            "Epoch 132: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.5941e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.6287e-04 - val_root_mean_squared_error: 0.0128\n",
            "Epoch 133/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2240e-04 - root_mean_squared_error: 0.0180\n",
            "Epoch 133: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6109e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.4607e-04 - val_root_mean_squared_error: 0.0157\n",
            "Epoch 134/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.2993e-04 - root_mean_squared_error: 0.0152\n",
            "Epoch 134: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.6424e-04 - root_mean_squared_error: 0.0191 - val_loss: 1.5260e-04 - val_root_mean_squared_error: 0.0124\n",
            "Epoch 135/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1009e-04 - root_mean_squared_error: 0.0203\n",
            "Epoch 135: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.5649e-04 - root_mean_squared_error: 0.0189 - val_loss: 5.6783e-05 - val_root_mean_squared_error: 0.0075\n",
            "Epoch 136/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9024e-04 - root_mean_squared_error: 0.0198\n",
            "Epoch 136: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.6986e-04 - root_mean_squared_error: 0.0192 - val_loss: 8.0392e-05 - val_root_mean_squared_error: 0.0090\n",
            "Epoch 137/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7438e-04 - root_mean_squared_error: 0.0193\n",
            "Epoch 137: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.6245e-04 - root_mean_squared_error: 0.0190 - val_loss: 2.6762e-04 - val_root_mean_squared_error: 0.0164\n",
            "Epoch 138/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.8316e-04 - root_mean_squared_error: 0.0196\n",
            "Epoch 138: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.6489e-04 - root_mean_squared_error: 0.0191 - val_loss: 2.2700e-04 - val_root_mean_squared_error: 0.0151\n",
            "Epoch 139/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.9373e-04 - root_mean_squared_error: 0.0198\n",
            "Epoch 139: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.5797e-04 - root_mean_squared_error: 0.0189 - val_loss: 1.0138e-04 - val_root_mean_squared_error: 0.0101\n",
            "Epoch 140/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.6837e-04 - root_mean_squared_error: 0.0192\n",
            "Epoch 140: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6369e-04 - root_mean_squared_error: 0.0191 - val_loss: 7.5653e-05 - val_root_mean_squared_error: 0.0087\n",
            "Epoch 141/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.3752e-04 - root_mean_squared_error: 0.0209\n",
            "Epoch 141: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.6132e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.8234e-04 - val_root_mean_squared_error: 0.0135\n",
            "Epoch 142/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.6735e-04 - root_mean_squared_error: 0.0164\n",
            "Epoch 142: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3.6541e-04 - root_mean_squared_error: 0.0191 - val_loss: 2.7631e-04 - val_root_mean_squared_error: 0.0166\n",
            "Epoch 143/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1665e-04 - root_mean_squared_error: 0.0204\n",
            "Epoch 143: val_loss did not improve from 0.00004\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.5995e-04 - root_mean_squared_error: 0.0190 - val_loss: 1.2754e-04 - val_root_mean_squared_error: 0.0113\n",
            "Epoch 143: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "test_predicted = model.predict(X_test)"
      ],
      "metadata": {
        "id": "pb7syksNmRhG"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply inverse transformation\n",
        "test_predicted= scaler.inverse_transform(test_predicted)\n",
        "#Y_test = scaler.inverse_transform(Y_test)\n",
        "#test_predicted = test_predicted.reshape(test_predicted.shape[0],test_predicted.shape[1])\n",
        "#test_predicted.shape"
      ],
      "metadata": {
        "id": "--JQahZGmRml"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_test.shape\n",
        "#test_predicted.shape\n",
        "#test_predicted = test_predicted.reshape(test_predicted.shape[0])\n",
        "test_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS0Msv5LZbtT",
        "outputId": "c83e6d1e-1470-47b4-eff7-c70c2d82eda2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([222.55663, 223.38861, 224.32755, 225.43228, 226.41525, 227.15703,\n",
              "       227.90218, 228.52032, 229.32317, 230.21187, 231.20364, 232.28741,\n",
              "       233.37494, 234.44821, 235.61697, 236.88129, 238.33109, 239.7339 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-populate Y_test\n",
        "#X_test, Y_test = create_dmatrix(test_set, time_step)\n",
        "#Y_test = Y_test.reshape(test_predicted.shape[0],1)\n",
        "#Y_test = scaler.inverse_transform(Y_test)\n",
        "Y_test = Y_test.reshape(-1)\n",
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQEQ4jxRdRT6",
        "outputId": "656a13a8-ecc4-428a-c37c-e7aff9babc52"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([219.14463903, 219.79275285, 220.57041794, 221.70518811,\n",
              "       222.92313866, 223.79606296, 224.7245786 , 225.43047908,\n",
              "       227.02634156, 229.16505202, 230.73607244, 231.45046524,\n",
              "       231.83269223, 232.80002415, 235.63291781, 238.22681998,\n",
              "       241.91043322, 245.02071711])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Y_test to 2D\n",
        "Y_test = Y_test.reshape(test_predicted.shape[0],1)\n",
        "Y_test = scaler.inverse_transform(Y_test)\n",
        "\n",
        "# Reshape back to 1D\n",
        "Y_test = Y_test.reshape(test_predicted.shape[0])\n",
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oORwiQCfb4fa",
        "outputId": "cbee3865-d301-4e9c-aa9a-d4bce8b363ce"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.95993694e+10, 4.97453658e+10, 4.99205454e+10, 5.01761677e+10,\n",
              "       5.04505275e+10, 5.06471655e+10, 5.08563262e+10, 5.10153398e+10,\n",
              "       5.13748294e+10, 5.18566029e+10, 5.22104964e+10, 5.23714231e+10,\n",
              "       5.24575249e+10, 5.26754295e+10, 5.33135770e+10, 5.38978885e+10,\n",
              "       5.47276722e+10, 5.54283057e+10])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE\n",
        "math.sqrt(mean_squared_error(Y_test,test_predicted))\n"
      ],
      "metadata": {
        "id": "qZQEG9Z3pLkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18799ae0-0958-469f-b5a6-022acedc4899"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8932155806631297"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_predicted = test_predicted.reshape(-1, 1)\n",
        "#test_predicted\n",
        "test_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRrYOIDqfulR",
        "outputId": "9d27f8a2-9c6f-44f4-e4ed-a29f7cae8416"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[222.55663],\n",
              "       [223.38861],\n",
              "       [224.32755],\n",
              "       [225.43228],\n",
              "       [226.41525],\n",
              "       [227.15703],\n",
              "       [227.90218],\n",
              "       [228.52032],\n",
              "       [229.32317],\n",
              "       [230.21187],\n",
              "       [231.20364],\n",
              "       [232.28741],\n",
              "       [233.37494],\n",
              "       [234.44821],\n",
              "       [235.61697],\n",
              "       [236.88129],\n",
              "       [238.33109],\n",
              "       [239.7339 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_predicted = model.predict(X_train)\n",
        "validation_predicted = model.predict(X_val)"
      ],
      "metadata": {
        "id": "AB30iYuZmfZu"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training_predicted = scaler.inverse_transform(training_predicted)\n",
        "#training_predicted.shape\n",
        "#validation_predicted = scaler.inverse_transform(validation_predicted)\n",
        "#validation_predicted.shape\n",
        "print(scaler.inverse_transform(validation_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymap5AWCmtC_",
        "outputId": "34c9a391-dda5-4def-db46-1d56ba764f11"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[195.52227904]\n",
            " [196.56334956]\n",
            " [197.21897219]\n",
            " [198.96773997]\n",
            " [200.01970483]\n",
            " [201.95115829]\n",
            " [203.03163447]\n",
            " [204.65713353]\n",
            " [205.50370861]\n",
            " [206.36003519]\n",
            " [206.93065877]\n",
            " [207.71988729]\n",
            " [209.17786562]\n",
            " [210.20798447]\n",
            " [211.30094292]\n",
            " [212.29424721]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting everything together\n",
        "# Setting the intervals \n",
        "\n",
        "# shift training predictions for plotting\n",
        "training_predicted_plot = np.empty_like(df1)\n",
        "training_predicted_plot[:, :] = np.nan\n",
        "#training_predicted.shape\n",
        "training_predicted_plot[0:55, :] = training_predicted\n",
        "\n",
        "# shift validation predictions for plotting\n",
        "val_predicted_plot = np.empty_like(df1)\n",
        "val_predicted_plot[:, :] = np.nan\n",
        "#validation_predicted.shape\n",
        "val_predicted_plot[69:76, :] = validation_predicted\n",
        "\n",
        "\n",
        "# shift test predictions for plotting\n",
        "test_predicted_plot = np.empty_like(df1)\n",
        "test_predicted_plot[:, :] = np.nan\n",
        "#test_predicted.shape\n",
        "test_predicted_plot[89:107, :] = test_predicted\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(df1), label = \"Real Data\")\n",
        "plt.plot(test_predicted_plot, label = \"Predicted Data for Test Set\")\n",
        "plt.plot(val_predicted_plot, label = \"Predicted Data for Validation Set\")\n",
        "plt.plot(training_predicted_plot, label = \"Predicted Data for Training Set\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "475ZyW85pnN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "459f496f-959c-4210-8b7c-34c4264bbad7"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}